seed_everything: 6785326
# ckpt_path: last
# define the training
trainer:
  # Work directory for the session
  default_root_dir: /scratch/usr/bepmusil/opep/results/torchmd_net/test_0
  max_epochs: 150
  max_time: null
  strategy: ddp_find_unused_parameters_false
  accelerator: gpu
  devices: 4
  precision: 32 # 32 bf16
  plugins:
    - class_path: pytorch_lightning.plugins.environments.SLURMEnvironment
      init_args: {}
  logger:
    - class_path: pytorch_lightning.loggers.TensorBoardLogger
      init_args:
        save_dir: default_root_dir
        name: tensorboard
        version: ''
  benchmark: false
  enable_checkpointing: true
  callbacks:
    - class_path: pytorch_lightning.callbacks.LearningRateMonitor
      init_args:
        logging_interval: epoch
        log_momentum: false
    - class_path: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint
      init_args:
        dirpath: default_root_dir
        monitor: validation_loss
        save_top_k: -1
        every_n_epochs: 1
        filename: '{epoch}-{validation_loss:.4f}'
        save_last: true
    - class_path: pytorch_lightning.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 20
  log_every_n_steps: 500
  gradient_clip_val: 0
  gradient_clip_algorithm: norm
  track_grad_norm: -1
  check_val_every_n_epoch: 1
  fast_dev_run: false
  accumulate_grad_batches: 8 #
  enable_model_summary: false
  deterministic: false
  auto_lr_find: false
  detect_anomaly: false # setting this to true enables detection of NaN after every small-batch update, but will slow down the training by 30%~50%
  replace_sampler_ddp: false # see https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#replace-sampler-ddp for details
  enable_progress_bar: true # uncomment this in production (e.g., when redirecting the stdout to a file), otherwise it will generate huge a huge log file and harm the disk
optimizer:
  class_path: torch.optim.Adam # torch.optim.Adam # torch_optimizer.Lamb
  init_args:
    lr: 0.0001
lr_scheduler:
  class_path: pytorch_lightning.cli.ReduceLROnPlateau
  init_args:
    factor: 0.8
    patience: 3
    min_lr: 0.000001
    monitor: validation_loss
data:
  h5_file_path: /scratch/musil/opep/results/torchmd_net/cln_delta_dataset.h5
  loading_options:
    hdf_key_mapping:
      coords: cg_coords
      embeds: attrs:cg_embeds
      forces: cg_delta_forces
  partition_options: ./partition.yaml



